---
title: "Web Scraping"
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'index.html'))})
author: "Jake Bersabe"
output: 
  html_document:
    css: "style.css"
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
```

## Import Libraries  

Let me walk you through my process of web scraping. I'm only a beginner so bear with me. \

I will use `rvest` for web scraping and `stringr` for string manipulation.  \
```{r}
library(rvest)
library(stringr)
library(dplyr)
```

## Source Website  

I'm going to scrape from IMDB's website. Save the contents of the `url` to `top_movies` using the `read_html` function.  \
```{r}
url <- "https://www.imdb.com/chart/top"

top_movies <- read_html(url)
```


## Titles

Provide the `css` element to `html_nodes` and then use `html_text` to extract the texts from the nodes. I used [SelectorGadget](https://selectorgadget.com/) to easily detect the target `css` elements. The second line of code removed the unnecessary strings in the titles.  
```{r}
titles <- top_movies %>% 
  html_nodes(".titleColumn a") %>% 
  html_text()
  
titles <- titles[!titles %in% c("", " ")]
titles[1:10]

```


## Year

The `years` was extracted similarly. `str_sub` extracted the year from within the parentheses.  
```{r}
years <- top_movies %>% 
  html_nodes(".secondaryInfo") %>% 
  html_text() %>% 
  str_sub(2,-2) %>% 
  as.integer()

years
```


## Ratings

Extracting the rating is pretty straight-forward, just follow the previous procedures.  
```{r}
ratings <- top_movies %>% 
  html_nodes("strong") %>% 
  html_text() %>% 
  as.numeric()

ratings
```

## Director  

### Scrape links

Extracting the director of the movies from the website is not so simple. First, the links leading to the individual pages for the movies were scraped and stored to variable `links`. The links contain several details about the movies (including the director, especially).  

The `html_attr()` function was used this time to extract not the texts but the `hrefs`.  
```{r}
links <- top_movies %>% 
  html_nodes(".titleColumn a") %>% 
  html_attr("href") %>% 
  paste0("https://www.imdb.com", .)

links[1:3]


```

### Scrape Movie Details From `links`  

The following code extracted the details of the movie for the first link (for the top 1 movie) `links[1]`. The first element in the resulting vector contains the name of the director.  

```{r}
links[1] %>% 
  read_html() %>% 
  html_nodes("div.ipc-metadata-list-item__content-container") %>% 
  html_text()
```




The preceding process was repeated, but this time it was applied to a loop to extract details from all the links.  


[This stackoverflow answer helped me greatly.](https://stackoverflow.com/questions/21173774/split-string-when-a-capital-letter-follows-a-lower-cap-letter-in-the-middle-of-a)
```{r}
directors <- lapply(links, function(link) {
  details <- read_html(link) %>% 
  html_nodes("div.ipc-metadata-list-item__content-container") %>% 
  html_text()
  
  return(details[1])
}) %>% 
  unlist()

# I did a little bit of string manipulation here to separate 
# directors in films having multiple directors

# First, I replaced strings within () with a whitespace
# Then I split the strings where a lowercase letter is next to an uppercase letter.
directors <- directors %>% 
  str_replace_all("\\([^()]+\\)", " ") %>% 
  str_split("(?<=[[:lower:]])(?=[[:upper:][:digit:](])")

# This chunk of code is an attempt to unlist the `directors` variable 
# which turned out to be not so simple task.
directors <- lapply(1:250, function(x) {
  
  if (length(directors[[x]]) == 2) {
    paste(directors[[x]][1], directors[[x]][2], sep = ", ")
  } else if (length(directors[[x]]) == 3) {
    paste(directors[[x]][1], directors[[x]][2], directors[[x]][3], sep = ", ")
  } else {
    directors[[x]]
  }
    
}) %>% 
  unlist()


directors[1:16]
```

## Writers

The writers were scraped using a code very similar to the previous code. The detail about the writer is stored in the 2nd element of the vector (`details[2]`).  

The `str_replace_all()` function removed the unnecessary details about the writers and `str_sub(1, -2)` removed the comma at the end of each string.  

```{r}
writers <- lapply(links, function(link) {
  details <- read_html(link) %>% 
  html_nodes("div.ipc-metadata-list-item__content-container") %>% 
  html_text()
  
  return(details[2])
}) %>% 
  unlist()

writers <- writers %>% 
  str_replace_all("\\([^()]+\\)", ", ") %>% 
  str_squish() %>% 
  str_sub(1, -2)
  
writers[1:10]
```


## Create Data Frame

Finally, create a data frame to compile all our extracted movie details.  

```{r}
imdb_top_250 <- tibble(rank = 1:250,
                       title = titles,
                       rating = ratings,
                       director = directors,
                       writer = writers)

imdb_top_250 %>% head(10) %>% knitr::kable()
```







